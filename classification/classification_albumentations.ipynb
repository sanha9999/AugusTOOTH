{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import albumentations\n",
    "import albumentations.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dir = \"D:/jupyter_proj/AugusTOOTH/classification/data\"\n",
    "        self.filenames = os.listdir(self.img_dir)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = MakeLabel(self.filenames[index])\n",
    "        img_path = os.path.join(self.img_dir, self.filenames[index])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR -> RGB\n",
    "        # albumentations 라이브러리를 사용할 것인데, PIL을 쓰면 변환이 안된다하여 cv2로 변환해준다.\n",
    "        # img = np.asarray_chkfinite(Image.open(img_path))\n",
    "        \n",
    "        if img.dtype == np.uint8:\n",
    "            img = img / 255.0\n",
    "        \n",
    "        img = ToTensor(img)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        #  print(np.shape(img)) # 검사코드\n",
    "        input = {'data' : img, 'label' : label}\n",
    "        cnt +=1\n",
    "        return input\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.filenames)\n",
    "\n",
    "    \n",
    "def MakeLabel(filenames):\n",
    "    input_img = filenames\n",
    "    if \"O\" in input_img:\n",
    "        label = F.one_hot(torch.tensor(0), 2)\n",
    "    else : label = F.one_hot(torch.tensor(1), 2)\n",
    "\n",
    "    return label\n",
    "\n",
    "def ToTensor(image):\n",
    "    image = image.transpose((2,0,1)).astype(np.float32)\n",
    "    image = torch.from_numpy(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albumentations train\n",
    "\n",
    "albumentations_train = albumentations.Compose([\n",
    "    albumentations.Resize(height=256, width=256),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.HorizontalFlip(p=0.8),\n",
    "        albumentations.RandomRotate90(p=0.8),\n",
    "        albumentations.VerticalFlip(p=0.8)\n",
    "    ], p=1),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(p=0.75),\n",
    "        albumentations.OpticalDistortion(p=0.75),\n",
    "        albumentations.GaussNoise(p=0.75)\n",
    "    ], p=1),\n",
    "    albumentations.pytorch.ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = Dataset(transform = albumentations_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_datset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_datset, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(ResNet50)\n",
    "\n",
    "import torchvision.models.resnet as resnet\n",
    "import torch.optim as optim\n",
    "\n",
    "conv1x1 = resnet.conv1x1\n",
    "Bottleneck = resnet.Bottleneck\n",
    "BasicBlock = resnet.BasicBlock\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=2, zero_init_residual=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 32\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False) # 마찬가지로 전부 사이즈 조정\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 32, layers[0], stride=1) # 3 반복\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2) # 4 반복\n",
    "        self.layer3 = self._make_layer(block, 128, layers[2], stride=2) # 6 반복\n",
    "        self.layer4 = self._make_layer(block, 256, layers[3], stride=2) # 3 반복\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
    "\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1): # planes -> 입력되는 채널 수\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion: \n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input [32, 128, 128] -> [C ,H, W]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        #x.shape =[32, 64, 64]\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        #x.shape =[128, 64, 64]\n",
    "        x = self.layer2(x)\n",
    "        #x.shape =[256, 32, 32]\n",
    "        x = self.layer3(x)\n",
    "        #x.shape =[512, 16, 16]\n",
    "        x = self.layer4(x)\n",
    "        #x.shape =[1024, 8, 8]\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = ResNet(resnet.Bottleneck, [3,4,6,3], 2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 128]             864\n",
      "       BatchNorm2d-2         [-1, 32, 128, 128]              64\n",
      "              ReLU-3         [-1, 32, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 32, 64, 64]               0\n",
      "            Conv2d-5           [-1, 32, 64, 64]           1,024\n",
      "       BatchNorm2d-6           [-1, 32, 64, 64]              64\n",
      "              ReLU-7           [-1, 32, 64, 64]               0\n",
      "            Conv2d-8           [-1, 32, 64, 64]           9,216\n",
      "       BatchNorm2d-9           [-1, 32, 64, 64]              64\n",
      "             ReLU-10           [-1, 32, 64, 64]               0\n",
      "           Conv2d-11          [-1, 128, 64, 64]           4,096\n",
      "      BatchNorm2d-12          [-1, 128, 64, 64]             256\n",
      "           Conv2d-13          [-1, 128, 64, 64]           4,096\n",
      "      BatchNorm2d-14          [-1, 128, 64, 64]             256\n",
      "             ReLU-15          [-1, 128, 64, 64]               0\n",
      "       Bottleneck-16          [-1, 128, 64, 64]               0\n",
      "           Conv2d-17           [-1, 32, 64, 64]           4,096\n",
      "      BatchNorm2d-18           [-1, 32, 64, 64]              64\n",
      "             ReLU-19           [-1, 32, 64, 64]               0\n",
      "           Conv2d-20           [-1, 32, 64, 64]           9,216\n",
      "      BatchNorm2d-21           [-1, 32, 64, 64]              64\n",
      "             ReLU-22           [-1, 32, 64, 64]               0\n",
      "           Conv2d-23          [-1, 128, 64, 64]           4,096\n",
      "      BatchNorm2d-24          [-1, 128, 64, 64]             256\n",
      "             ReLU-25          [-1, 128, 64, 64]               0\n",
      "       Bottleneck-26          [-1, 128, 64, 64]               0\n",
      "           Conv2d-27           [-1, 32, 64, 64]           4,096\n",
      "      BatchNorm2d-28           [-1, 32, 64, 64]              64\n",
      "             ReLU-29           [-1, 32, 64, 64]               0\n",
      "           Conv2d-30           [-1, 32, 64, 64]           9,216\n",
      "      BatchNorm2d-31           [-1, 32, 64, 64]              64\n",
      "             ReLU-32           [-1, 32, 64, 64]               0\n",
      "           Conv2d-33          [-1, 128, 64, 64]           4,096\n",
      "      BatchNorm2d-34          [-1, 128, 64, 64]             256\n",
      "             ReLU-35          [-1, 128, 64, 64]               0\n",
      "       Bottleneck-36          [-1, 128, 64, 64]               0\n",
      "           Conv2d-37           [-1, 64, 64, 64]           8,192\n",
      "      BatchNorm2d-38           [-1, 64, 64, 64]             128\n",
      "             ReLU-39           [-1, 64, 64, 64]               0\n",
      "           Conv2d-40           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-41           [-1, 64, 32, 32]             128\n",
      "             ReLU-42           [-1, 64, 32, 32]               0\n",
      "           Conv2d-43          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-44          [-1, 256, 32, 32]             512\n",
      "           Conv2d-45          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-46          [-1, 256, 32, 32]             512\n",
      "             ReLU-47          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-48          [-1, 256, 32, 32]               0\n",
      "           Conv2d-49           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-50           [-1, 64, 32, 32]             128\n",
      "             ReLU-51           [-1, 64, 32, 32]               0\n",
      "           Conv2d-52           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-53           [-1, 64, 32, 32]             128\n",
      "             ReLU-54           [-1, 64, 32, 32]               0\n",
      "           Conv2d-55          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-56          [-1, 256, 32, 32]             512\n",
      "             ReLU-57          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-58          [-1, 256, 32, 32]               0\n",
      "           Conv2d-59           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-60           [-1, 64, 32, 32]             128\n",
      "             ReLU-61           [-1, 64, 32, 32]               0\n",
      "           Conv2d-62           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-63           [-1, 64, 32, 32]             128\n",
      "             ReLU-64           [-1, 64, 32, 32]               0\n",
      "           Conv2d-65          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-66          [-1, 256, 32, 32]             512\n",
      "             ReLU-67          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-68          [-1, 256, 32, 32]               0\n",
      "           Conv2d-69           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-70           [-1, 64, 32, 32]             128\n",
      "             ReLU-71           [-1, 64, 32, 32]               0\n",
      "           Conv2d-72           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-73           [-1, 64, 32, 32]             128\n",
      "             ReLU-74           [-1, 64, 32, 32]               0\n",
      "           Conv2d-75          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-76          [-1, 256, 32, 32]             512\n",
      "             ReLU-77          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-78          [-1, 256, 32, 32]               0\n",
      "           Conv2d-79          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-80          [-1, 128, 32, 32]             256\n",
      "             ReLU-81          [-1, 128, 32, 32]               0\n",
      "           Conv2d-82          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-83          [-1, 128, 16, 16]             256\n",
      "             ReLU-84          [-1, 128, 16, 16]               0\n",
      "           Conv2d-85          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-86          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-87          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-88          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-89          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-90          [-1, 512, 16, 16]               0\n",
      "           Conv2d-91          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-92          [-1, 128, 16, 16]             256\n",
      "             ReLU-93          [-1, 128, 16, 16]               0\n",
      "           Conv2d-94          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-95          [-1, 128, 16, 16]             256\n",
      "             ReLU-96          [-1, 128, 16, 16]               0\n",
      "           Conv2d-97          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-98          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-99          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-100          [-1, 512, 16, 16]               0\n",
      "          Conv2d-101          [-1, 128, 16, 16]          65,536\n",
      "     BatchNorm2d-102          [-1, 128, 16, 16]             256\n",
      "            ReLU-103          [-1, 128, 16, 16]               0\n",
      "          Conv2d-104          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-105          [-1, 128, 16, 16]             256\n",
      "            ReLU-106          [-1, 128, 16, 16]               0\n",
      "          Conv2d-107          [-1, 512, 16, 16]          65,536\n",
      "     BatchNorm2d-108          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-109          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-110          [-1, 512, 16, 16]               0\n",
      "          Conv2d-111          [-1, 128, 16, 16]          65,536\n",
      "     BatchNorm2d-112          [-1, 128, 16, 16]             256\n",
      "            ReLU-113          [-1, 128, 16, 16]               0\n",
      "          Conv2d-114          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-115          [-1, 128, 16, 16]             256\n",
      "            ReLU-116          [-1, 128, 16, 16]               0\n",
      "          Conv2d-117          [-1, 512, 16, 16]          65,536\n",
      "     BatchNorm2d-118          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-119          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-120          [-1, 512, 16, 16]               0\n",
      "          Conv2d-121          [-1, 128, 16, 16]          65,536\n",
      "     BatchNorm2d-122          [-1, 128, 16, 16]             256\n",
      "            ReLU-123          [-1, 128, 16, 16]               0\n",
      "          Conv2d-124          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-125          [-1, 128, 16, 16]             256\n",
      "            ReLU-126          [-1, 128, 16, 16]               0\n",
      "          Conv2d-127          [-1, 512, 16, 16]          65,536\n",
      "     BatchNorm2d-128          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-129          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-130          [-1, 512, 16, 16]               0\n",
      "          Conv2d-131          [-1, 128, 16, 16]          65,536\n",
      "     BatchNorm2d-132          [-1, 128, 16, 16]             256\n",
      "            ReLU-133          [-1, 128, 16, 16]               0\n",
      "          Conv2d-134          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-135          [-1, 128, 16, 16]             256\n",
      "            ReLU-136          [-1, 128, 16, 16]               0\n",
      "          Conv2d-137          [-1, 512, 16, 16]          65,536\n",
      "     BatchNorm2d-138          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-139          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-140          [-1, 512, 16, 16]               0\n",
      "          Conv2d-141          [-1, 256, 16, 16]         131,072\n",
      "     BatchNorm2d-142          [-1, 256, 16, 16]             512\n",
      "            ReLU-143          [-1, 256, 16, 16]               0\n",
      "          Conv2d-144            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-145            [-1, 256, 8, 8]             512\n",
      "            ReLU-146            [-1, 256, 8, 8]               0\n",
      "          Conv2d-147           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-148           [-1, 1024, 8, 8]           2,048\n",
      "          Conv2d-149           [-1, 1024, 8, 8]         524,288\n",
      "     BatchNorm2d-150           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-151           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-152           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-153            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-154            [-1, 256, 8, 8]             512\n",
      "            ReLU-155            [-1, 256, 8, 8]               0\n",
      "          Conv2d-156            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-157            [-1, 256, 8, 8]             512\n",
      "            ReLU-158            [-1, 256, 8, 8]               0\n",
      "          Conv2d-159           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-160           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-161           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-162           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-163            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-164            [-1, 256, 8, 8]             512\n",
      "            ReLU-165            [-1, 256, 8, 8]               0\n",
      "          Conv2d-166            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-167            [-1, 256, 8, 8]             512\n",
      "            ReLU-168            [-1, 256, 8, 8]               0\n",
      "          Conv2d-169           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-170           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-171           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-172           [-1, 1024, 8, 8]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 1024, 1, 1]               0\n",
      "          Linear-174                    [-1, 2]           2,050\n",
      "================================================================\n",
      "Total params: 5,890,850\n",
      "Trainable params: 5,890,850\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 187.13\n",
      "Params size (MB): 22.47\n",
      "Estimated Total Size (MB): 209.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(resnet50, input_size=(3, 128, 128))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
