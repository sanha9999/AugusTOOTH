{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cfb6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import albumentations\n",
    "import albumentations.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "294e6c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(777)\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7957a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_dir = \"/home/temp_1/kangsanha/malocclusion/data\"\n",
    "        self.filenames = os.listdir(self.img_dir)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = MakeLabel(self.filenames[index])\n",
    "        img_path = os.path.join(self.img_dir, self.filenames[index])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR -> RGB\n",
    "        # albumentations 라이브러리를 사용할 것인데, PIL을 쓰면 변환이 안된다하여 cv2로 변환해준다.\n",
    "        # img = np.asarray_chkfinite(Image.open(img_path))\n",
    "        \n",
    "        if img.dtype == np.uint8:\n",
    "            img = img / 255.0\n",
    "        \n",
    "        #img = ToTensor(img)\n",
    "        #print(type(img))\n",
    "        #print(np.shape(img))\n",
    "        #img = img.transpose((2,0,1)).astype(np.float32)\n",
    "        if self.transform:\n",
    "            aug = self.transform(image=img)\n",
    "            img = aug['image']\n",
    "        #img = img.values()\n",
    "        \n",
    "        #  print(np.shape(img)) # 검사코드\n",
    "        # input = {'data' : img, 'label' : label}\n",
    "        \n",
    "        return img, label\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.filenames)\n",
    "\n",
    "    \n",
    "def MakeLabel(filenames):\n",
    "    input_img = filenames\n",
    "    if \"O\" in input_img:\n",
    "        label = 1#label = F.one_hot(torch.tensor(0), 2)\n",
    "    else : label = 0#label = F.one_hot(torch.tensor(1), 2)\n",
    "\n",
    "    return label\n",
    "\n",
    "def ToTensor(image):\n",
    "    image = image.transpose((2,0,1)).astype(np.float32)\n",
    "    image = torch.from_numpy(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dffff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# albumentations train\n",
    "\n",
    "albumentations_train = albumentations.Compose([\n",
    "    albumentations.Resize(height=256, width=256),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.HorizontalFlip(p=0.8),\n",
    "        albumentations.RandomRotate90(p=0.8),\n",
    "        albumentations.VerticalFlip(p=0.8)\n",
    "    ], p=1),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(p=0.75),\n",
    "        albumentations.OpticalDistortion(p=0.75),\n",
    "        albumentations.GaussNoise(p=0.75)\n",
    "    ], p=1),\n",
    "    albumentations.pytorch.ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e871608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = Dataset(transform = albumentations_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42ff3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.7350, 0.7356, 0.7378,  ..., 0.6962, 0.7059, 0.7044],\n",
       "          [0.7333, 0.7349, 0.7351,  ..., 0.7193, 0.7214, 0.7163],\n",
       "          [0.7323, 0.7374, 0.7360,  ..., 0.7145, 0.7226, 0.7243],\n",
       "          ...,\n",
       "          [0.3920, 0.3892, 0.3900,  ..., 0.6817, 0.6747, 0.6775],\n",
       "          [0.3936, 0.4000, 0.3982,  ..., 0.6845, 0.6805, 0.6875],\n",
       "          [0.3980, 0.3903, 0.3940,  ..., 0.6908, 0.6975, 0.6938]],\n",
       " \n",
       "         [[0.5225, 0.5231, 0.5279,  ..., 0.4811, 0.4928, 0.4952],\n",
       "          [0.5236, 0.5256, 0.5243,  ..., 0.5043, 0.5065, 0.5004],\n",
       "          [0.5249, 0.5282, 0.5325,  ..., 0.4908, 0.5054, 0.5062],\n",
       "          ...,\n",
       "          [0.2538, 0.2510, 0.2594,  ..., 0.5452, 0.5364, 0.5425],\n",
       "          [0.2581, 0.2643, 0.2653,  ..., 0.5436, 0.5367, 0.5533],\n",
       "          [0.2677, 0.2605, 0.2603,  ..., 0.5539, 0.5613, 0.5629]],\n",
       " \n",
       "         [[0.4134, 0.4156, 0.4204,  ..., 0.3671, 0.3735, 0.3776],\n",
       "          [0.4124, 0.4185, 0.4168,  ..., 0.3898, 0.3901, 0.3818],\n",
       "          [0.4137, 0.4168, 0.4204,  ..., 0.3712, 0.3843, 0.3881],\n",
       "          ...,\n",
       "          [0.2276, 0.2222, 0.2287,  ..., 0.5105, 0.5035, 0.5069],\n",
       "          [0.2278, 0.2370, 0.2407,  ..., 0.5084, 0.5011, 0.5201],\n",
       "          [0.2387, 0.2302, 0.2329,  ..., 0.5182, 0.5238, 0.5256]]],\n",
       "        dtype=torch.float64),\n",
       " 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6e26182",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_datset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f82a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_datset, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1d10210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(ResNet50)\n",
    "\n",
    "import torchvision.models.resnet as resnet\n",
    "import torch.optim as optim\n",
    "\n",
    "conv1x1 = resnet.conv1x1\n",
    "Bottleneck = resnet.Bottleneck\n",
    "BasicBlock = resnet.BasicBlock\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=2, zero_init_residual=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 32\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False) # 마찬가지로 전부 사이즈 조정\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 32, layers[0], stride=1) # 3 반복\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2) # 4 반복\n",
    "        self.layer3 = self._make_layer(block, 128, layers[2], stride=2) # 6 반복\n",
    "        self.layer4 = self._make_layer(block, 256, layers[3], stride=2) # 3 반복\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
    "\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1): # planes -> 입력되는 채널 수\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion: \n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input [32, 128, 128] -> [C ,H, W]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        #x.shape =[32, 64, 64]\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        #x.shape =[128, 64, 64]\n",
    "        x = self.layer2(x)\n",
    "        #x.shape =[256, 32, 32]\n",
    "        x = self.layer3(x)\n",
    "        #x.shape =[512, 16, 16]\n",
    "        x = self.layer4(x)\n",
    "        #x.shape =[1024, 8, 8]\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed06ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = ResNet(resnet.Bottleneck, [3,4,6,3], 2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3d4e8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d53c2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정의\n",
    "optimizer = torch.optim.Adam(resnet50.parameters(), lr=1e-5)\n",
    "loss_func = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f53855b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 128]             864\n",
      "       BatchNorm2d-2         [-1, 32, 128, 128]              64\n",
      "              ReLU-3         [-1, 32, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 32, 64, 64]               0\n",
      "            Conv2d-5           [-1, 32, 64, 64]           1,024\n",
      "       BatchNorm2d-6           [-1, 32, 64, 64]              64\n",
      "              ReLU-7           [-1, 32, 64, 64]               0\n",
      "            Conv2d-8           [-1, 32, 64, 64]           9,216\n",
      "       BatchNorm2d-9           [-1, 32, 64, 64]              64\n",
      "             ReLU-10           [-1, 32, 64, 64]               0\n",
      "           Conv2d-11          [-1, 128, 64, 64]           4,096\n",
      "      BatchNorm2d-12          [-1, 128, 64, 64]             256\n",
      "           Conv2d-13          [-1, 128, 64, 64]           4,096\n",
      "      BatchNorm2d-14          [-1, 128, 64, 64]             256\n",
      "             ReLU-15          [-1, 128, 64, 64]               0\n",
      "       Bottleneck-16          [-1, 128, 64, 64]               0\n",
      "           Conv2d-17           [-1, 32, 64, 64]           4,096\n",
      "      BatchNorm2d-18           [-1, 32, 64, 64]              64\n",
      "             ReLU-19           [-1, 32, 64, 64]               0\n",
      "           Conv2d-20           [-1, 32, 64, 64]           9,216\n",
      "      BatchNorm2d-21           [-1, 32, 64, 64]              64\n",
      "             ReLU-22           [-1, 32, 64, 64]               0\n",
      "           Conv2d-23          [-1, 128, 64, 64]           4,096\n",
      "      BatchNorm2d-24          [-1, 128, 64, 64]             256\n",
      "             ReLU-25          [-1, 128, 64, 64]               0\n",
      "       Bottleneck-26          [-1, 128, 64, 64]               0\n",
      "           Conv2d-27           [-1, 32, 64, 64]           4,096\n",
      "      BatchNorm2d-28           [-1, 32, 64, 64]              64\n",
      "             ReLU-29           [-1, 32, 64, 64]               0\n",
      "           Conv2d-30           [-1, 32, 64, 64]           9,216\n",
      "      BatchNorm2d-31           [-1, 32, 64, 64]              64\n",
      "             ReLU-32           [-1, 32, 64, 64]               0\n",
      "           Conv2d-33          [-1, 128, 64, 64]           4,096\n",
      "      BatchNorm2d-34          [-1, 128, 64, 64]             256\n",
      "             ReLU-35          [-1, 128, 64, 64]               0\n",
      "       Bottleneck-36          [-1, 128, 64, 64]               0\n",
      "           Conv2d-37           [-1, 64, 64, 64]           8,192\n",
      "      BatchNorm2d-38           [-1, 64, 64, 64]             128\n",
      "             ReLU-39           [-1, 64, 64, 64]               0\n",
      "           Conv2d-40           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-41           [-1, 64, 32, 32]             128\n",
      "             ReLU-42           [-1, 64, 32, 32]               0\n",
      "           Conv2d-43          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-44          [-1, 256, 32, 32]             512\n",
      "           Conv2d-45          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-46          [-1, 256, 32, 32]             512\n",
      "             ReLU-47          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-48          [-1, 256, 32, 32]               0\n",
      "           Conv2d-49           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-50           [-1, 64, 32, 32]             128\n",
      "             ReLU-51           [-1, 64, 32, 32]               0\n",
      "           Conv2d-52           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-53           [-1, 64, 32, 32]             128\n",
      "             ReLU-54           [-1, 64, 32, 32]               0\n",
      "           Conv2d-55          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-56          [-1, 256, 32, 32]             512\n",
      "             ReLU-57          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-58          [-1, 256, 32, 32]               0\n",
      "           Conv2d-59           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-60           [-1, 64, 32, 32]             128\n",
      "             ReLU-61           [-1, 64, 32, 32]               0\n",
      "           Conv2d-62           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-63           [-1, 64, 32, 32]             128\n",
      "             ReLU-64           [-1, 64, 32, 32]               0\n",
      "           Conv2d-65          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-66          [-1, 256, 32, 32]             512\n",
      "             ReLU-67          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-68          [-1, 256, 32, 32]               0\n",
      "           Conv2d-69           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-70           [-1, 64, 32, 32]             128\n",
      "             ReLU-71           [-1, 64, 32, 32]               0\n",
      "           Conv2d-72           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-73           [-1, 64, 32, 32]             128\n",
      "             ReLU-74           [-1, 64, 32, 32]               0\n",
      "           Conv2d-75          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-76          [-1, 256, 32, 32]             512\n",
      "             ReLU-77          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-78          [-1, 256, 32, 32]               0\n",
      "           Conv2d-79          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-80          [-1, 128, 32, 32]             256\n",
      "             ReLU-81          [-1, 128, 32, 32]               0\n",
      "           Conv2d-82          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-83          [-1, 128, 16, 16]             256\n",
      "             ReLU-84          [-1, 128, 16, 16]               0\n",
      "           Conv2d-85          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-86          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-87          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-88          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-89          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-90          [-1, 512, 16, 16]               0\n",
      "           Conv2d-91          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-92          [-1, 128, 16, 16]             256\n",
      "             ReLU-93          [-1, 128, 16, 16]               0\n",
      "           Conv2d-94          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-95          [-1, 128, 16, 16]             256\n",
      "             ReLU-96          [-1, 128, 16, 16]               0\n",
      "           Conv2d-97          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-98          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-99          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-100          [-1, 512, 16, 16]               0\n",
      "          Conv2d-101          [-1, 128, 16, 16]          65,536\n",
      "     BatchNorm2d-102          [-1, 128, 16, 16]             256\n",
      "            ReLU-103          [-1, 128, 16, 16]               0\n",
      "          Conv2d-104          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-105          [-1, 128, 16, 16]             256\n",
      "            ReLU-106          [-1, 128, 16, 16]               0\n",
      "          Conv2d-107          [-1, 512, 16, 16]          65,536\n",
      "     BatchNorm2d-108          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-109          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-110          [-1, 512, 16, 16]               0\n",
      "          Conv2d-111          [-1, 128, 16, 16]          65,536\n",
      "     BatchNorm2d-112          [-1, 128, 16, 16]             256\n",
      "            ReLU-113          [-1, 128, 16, 16]               0\n",
      "          Conv2d-114          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-115          [-1, 128, 16, 16]             256\n",
      "            ReLU-116          [-1, 128, 16, 16]               0\n",
      "          Conv2d-117          [-1, 512, 16, 16]          65,536\n",
      "     BatchNorm2d-118          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-119          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-120          [-1, 512, 16, 16]               0\n",
      "          Conv2d-121          [-1, 128, 16, 16]          65,536\n",
      "     BatchNorm2d-122          [-1, 128, 16, 16]             256\n",
      "            ReLU-123          [-1, 128, 16, 16]               0\n",
      "          Conv2d-124          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-125          [-1, 128, 16, 16]             256\n",
      "            ReLU-126          [-1, 128, 16, 16]               0\n",
      "          Conv2d-127          [-1, 512, 16, 16]          65,536\n",
      "     BatchNorm2d-128          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-129          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-130          [-1, 512, 16, 16]               0\n",
      "          Conv2d-131          [-1, 128, 16, 16]          65,536\n",
      "     BatchNorm2d-132          [-1, 128, 16, 16]             256\n",
      "            ReLU-133          [-1, 128, 16, 16]               0\n",
      "          Conv2d-134          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-135          [-1, 128, 16, 16]             256\n",
      "            ReLU-136          [-1, 128, 16, 16]               0\n",
      "          Conv2d-137          [-1, 512, 16, 16]          65,536\n",
      "     BatchNorm2d-138          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-139          [-1, 512, 16, 16]               0\n",
      "      Bottleneck-140          [-1, 512, 16, 16]               0\n",
      "          Conv2d-141          [-1, 256, 16, 16]         131,072\n",
      "     BatchNorm2d-142          [-1, 256, 16, 16]             512\n",
      "            ReLU-143          [-1, 256, 16, 16]               0\n",
      "          Conv2d-144            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-145            [-1, 256, 8, 8]             512\n",
      "            ReLU-146            [-1, 256, 8, 8]               0\n",
      "          Conv2d-147           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-148           [-1, 1024, 8, 8]           2,048\n",
      "          Conv2d-149           [-1, 1024, 8, 8]         524,288\n",
      "     BatchNorm2d-150           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-151           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-152           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-153            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-154            [-1, 256, 8, 8]             512\n",
      "            ReLU-155            [-1, 256, 8, 8]               0\n",
      "          Conv2d-156            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-157            [-1, 256, 8, 8]             512\n",
      "            ReLU-158            [-1, 256, 8, 8]               0\n",
      "          Conv2d-159           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-160           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-161           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-162           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-163            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-164            [-1, 256, 8, 8]             512\n",
      "            ReLU-165            [-1, 256, 8, 8]               0\n",
      "          Conv2d-166            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-167            [-1, 256, 8, 8]             512\n",
      "            ReLU-168            [-1, 256, 8, 8]               0\n",
      "          Conv2d-169           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-170           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-171           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-172           [-1, 1024, 8, 8]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 1024, 1, 1]               0\n",
      "          Linear-174                    [-1, 2]           2,050\n",
      "================================================================\n",
      "Total params: 5,890,850\n",
      "Trainable params: 5,890,850\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 187.13\n",
      "Params size (MB): 22.47\n",
      "Estimated Total Size (MB): 209.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(resnet50, input_size=(3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e4c67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb25fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0000 / 0100 | BATCH 0135 / 0135 | LOSS 0.6648\n",
      "TRAIN: EPOCH 0001 / 0100 | BATCH 0135 / 0135 | LOSS 0.6624\n",
      "TRAIN: EPOCH 0002 / 0100 | BATCH 0135 / 0135 | LOSS 0.6605\n",
      "TRAIN: EPOCH 0003 / 0100 | BATCH 0135 / 0135 | LOSS 0.6607\n",
      "TRAIN: EPOCH 0004 / 0100 | BATCH 0135 / 0135 | LOSS 0.6578\n",
      "TRAIN: EPOCH 0005 / 0100 | BATCH 0135 / 0135 | LOSS 0.6576\n",
      "TRAIN: EPOCH 0006 / 0100 | BATCH 0135 / 0135 | LOSS 0.6550\n",
      "TRAIN: EPOCH 0007 / 0100 | BATCH 0135 / 0135 | LOSS 0.6504\n",
      "TRAIN: EPOCH 0008 / 0100 | BATCH 0135 / 0135 | LOSS 0.6452\n",
      "TRAIN: EPOCH 0009 / 0100 | BATCH 0135 / 0135 | LOSS 0.6529\n",
      "TRAIN: EPOCH 0010 / 0100 | BATCH 0135 / 0135 | LOSS 0.6504\n",
      "TRAIN: EPOCH 0011 / 0100 | BATCH 0135 / 0135 | LOSS 0.6522\n",
      "TRAIN: EPOCH 0012 / 0100 | BATCH 0135 / 0135 | LOSS 0.6429\n",
      "TRAIN: EPOCH 0013 / 0100 | BATCH 0135 / 0135 | LOSS 0.6488\n",
      "TRAIN: EPOCH 0014 / 0100 | BATCH 0135 / 0135 | LOSS 0.6576\n",
      "TRAIN: EPOCH 0015 / 0100 | BATCH 0135 / 0135 | LOSS 0.6458\n",
      "TRAIN: EPOCH 0016 / 0100 | BATCH 0135 / 0135 | LOSS 0.6477\n",
      "TRAIN: EPOCH 0017 / 0100 | BATCH 0135 / 0135 | LOSS 0.6542\n",
      "TRAIN: EPOCH 0018 / 0100 | BATCH 0135 / 0135 | LOSS 0.6488\n",
      "TRAIN: EPOCH 0019 / 0100 | BATCH 0135 / 0135 | LOSS 0.6466\n",
      "TRAIN: EPOCH 0020 / 0100 | BATCH 0135 / 0135 | LOSS 0.6505\n",
      "TRAIN: EPOCH 0021 / 0100 | BATCH 0135 / 0135 | LOSS 0.6437\n",
      "TRAIN: EPOCH 0022 / 0100 | BATCH 0135 / 0135 | LOSS 0.6522\n",
      "TRAIN: EPOCH 0023 / 0100 | BATCH 0135 / 0135 | LOSS 0.6493\n",
      "TRAIN: EPOCH 0024 / 0100 | BATCH 0135 / 0135 | LOSS 0.6452\n",
      "TRAIN: EPOCH 0025 / 0100 | BATCH 0135 / 0135 | LOSS 0.6446\n",
      "TRAIN: EPOCH 0026 / 0100 | BATCH 0135 / 0135 | LOSS 0.6350\n",
      "TRAIN: EPOCH 0027 / 0100 | BATCH 0135 / 0135 | LOSS 0.6502\n",
      "TRAIN: EPOCH 0028 / 0100 | BATCH 0135 / 0135 | LOSS 0.6562\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47914/4111582081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;31m# input data, label 분리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch-1.9.1-py3.8-linux-x86_64.egg/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch-1.9.1-py3.8-linux-x86_64.egg/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch-1.9.1-py3.8-linux-x86_64.egg/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch-1.9.1-py3.8-linux-x86_64.egg/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch-1.9.1-py3.8-linux-x86_64.egg/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_47914/288225918.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMakeLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# BGR -> RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# albumentations 라이브러리를 사용할 것인데, PIL을 쓰면 변환이 안된다하여 cv2로 변환해준다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "if mode == 'train':\n",
    "    for epoch in range(0 , 100):\n",
    "        resnet50.train()\n",
    "        loss_arr = []\n",
    "        for batch, data in enumerate(train_loader, 1):\n",
    "            inputs, labels = data # input data, label 분리\n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = resnet50(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_arr += [loss.item()]\n",
    "            \n",
    "         \n",
    "        print(\"TRAIN: EPOCH %04d / %04d | BATCH %04d / %04d | LOSS %.4f\" %\n",
    "                  (epoch, 100, batch, 135, np.mean(loss_arr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
