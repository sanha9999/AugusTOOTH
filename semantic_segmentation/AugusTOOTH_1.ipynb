{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#model = torchvision.models.segmentation.fcn_resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, mode=None, transform = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.img_dir = \"D:\\Desktop\\project\\AugusTOOTH\\project\\data\\img_data\"\n",
    "        self.json_dir = \"D:\\Desktop\\project\\AugusTOOTH\\project\\data\\json_data\"\n",
    "\n",
    "        self.transform = transform\n",
    "        self.to_tensor = ToTensor()\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.path = os.path.join(self.img_dir, 'train')\n",
    "            self.json_path = os.path.join(self.json_dir, 'train')\n",
    "        elif mode =='val':\n",
    "            self.path = os.path.join(self.img_dir, 'validation')\n",
    "            self.json_path = os.path.join(self.json_dir, 'validation')\n",
    "        else:\n",
    "            self.path = os.path.join(self.img_dir, 'test')\n",
    "            self.json_path = os.path.join(self.json_dir, 'test')\n",
    "        \n",
    "        self.filenames = os.listdir(self.path)\n",
    "        self.json_filenames = os.listdir(self.json_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label_img = self.label_image(idx)\n",
    "        img_path = os.path.join(self.path, self.filenames[idx])\n",
    "        img = np.asarray_chkfinite(Image.open(img_path)).astype(np.float32)\n",
    "        \n",
    "        \n",
    "        img = img / 255.0\n",
    "        \n",
    "        label_img = label_img / 255.0\n",
    "        \n",
    "        \n",
    "        input = {'data' : img, 'label' : label_img}\n",
    "        \n",
    "        input = self.to_tensor(input)\n",
    "        # print(type(label_img))\n",
    "        if self.transform :\n",
    "            input['data'] = self.transform(input['data'])\n",
    "            input['label'] = self.transform(input['label'])\n",
    "            \n",
    "        \n",
    "        return input\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def label_image(self, idx):\n",
    "        img_path = os.path.join(self.path, self.filenames[idx])\n",
    "        img = np.asarray_chkfinite(Image.open(img_path))\n",
    "        with open(os.path.join(self.json_path, self.json_filenames[idx]), 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "        \n",
    "        img2 = img.copy()\n",
    "        for i in range(0,len(json_data['annotations'])):\n",
    "            point = np.array(json_data['annotations'][i]['points'])\n",
    "            label_image = cv2.polylines(img, [point], True, (0, 0, 0))\n",
    "            label_image = cv2.fillPoly(label_image, [point], (0, 50, 150))\n",
    "        cv2.addWeighted(img, 0.5, img2, 0.5, 0, img2)    \n",
    "        img2 = img.astype(np.float32)\n",
    "        return img2\n",
    "class ToTensor(object):\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['data']\n",
    "\n",
    "        # Image의 numpy 차원 = (Y, X, CH)\n",
    "        # Image의 tensor 차원 = (CH, Y, X)\n",
    "        label = label.transpose((2, 0, 1)).astype(np.float32)\n",
    "        input = input.transpose((2, 0, 1)).astype(np.float32)\n",
    "\n",
    "        data = {'data': torch.from_numpy(input), 'label': torch.from_numpy(label) }\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'train':\n",
    "    transforms_train = transforms.Compose([transforms.ToPILImage(), transforms.Resize((512, 512)),transforms.ToTensor(),\n",
    "         ])\n",
    "    dataset_train = Dataset(mode = mode, transform = transforms_train)\n",
    "    load_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'val':\n",
    "    transforms_val = transforms.Compose([transforms.ToPILImage(), transforms.Resize((512, 512)), transforms.ToTensor()])\n",
    "    dataset_val = Dataset(mode = mode, transform = transforms_val)\n",
    "    load_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_train = len(dataset_train)\n",
    "num_data_val = len(dataset_val)\n",
    "\n",
    "num_batch_train = np.ceil(num_data_train / batch_size)\n",
    "num_batch_val = np.ceil(num_data_val / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'test':\n",
    "    transforms_test = transforms.Compose([transforms.Normalize(0.5, 0.5),transforms.ToTensor()])\n",
    "    dataset_test = Dataset(mode = 'test', transforms = transforms_test)\n",
    "    load_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2704, 4064, 3\n",
    "``` Python\n",
    "i=0\n",
    "for batch, data in enumerate(load_train, 1):\n",
    "    print(\"dd\")\n",
    "    label = data\n",
    "    i+=1\n",
    "    if i == 3:\n",
    "        break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd\n",
      "dd\n",
      "dd\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for batch, data in enumerate(load_train, 1):\n",
    "    print(\"dd\")\n",
    "    label = data\n",
    "    i+=1\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 512, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(label['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss func\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "## optimizer\n",
    "optim = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_train = SummaryWriter(log_dir=os.path.join('tensorboard', 'train') )\n",
    "writer_val = SummaryWriter(log_dir=os.path.join('tensorboard', 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_epoch = 0\n",
    "train_continue = 'off'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode=='train':\n",
    "    for epoch in range(0, num_epoch):\n",
    "        net.train()\n",
    "        loss_arr = []\n",
    "        for batch, data in enumerate(load_train, 1):\n",
    "            label = data['label']\n",
    "            input = data['data']\n",
    "            \n",
    "            output = net(input)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            \n",
    "            loss = loss_func(output, label)\n",
    "            loss.backward()\n",
    "            \n",
    "            optim.step()\n",
    "            \n",
    "            loss_arr += [loss.item()]\n",
    "            \n",
    "            print(\"TRAIN: EPOCH %04d / %04d | BATCH %04d / %04d | LOSS %.4f\" %\n",
    "                  (epoch, num_epoch, batch, num_batch_train, np.mean(loss_arr)))\n",
    "            \n",
    "        with torch.no_grad():\n",
    "                net.eval()\n",
    "                loss_arr = []\n",
    "\n",
    "                for batch, data in enumerate(load_val, 1):\n",
    "                    # forward pass\n",
    "                    label = data['label']\n",
    "                    input = data['data']\n",
    "\n",
    "                    output = net(input)\n",
    "\n",
    "                    # loss function\n",
    "                    loss = fn_loss(output, label)\n",
    "\n",
    "                    loss_arr += [loss.item()]\n",
    "\n",
    "                    print(\"VALID: EPOCH %04d / %04d | BATCH %04d / %04d | LOSS %.4f\" %\n",
    "                          (epoch, num_epoch, batch, num_batch_val, np.mean(loss_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\t\n",
    "        # Convolution, Batch_normalization, ReLU\n",
    "        def CBR2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)]\n",
    "            layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        # Contracting path (encoder)\n",
    "        self.enc1_1 = CBR2d(in_channels=3, out_channels=64) # , kernel_size=3, stride=1, padding=1, bias=True\n",
    "        self.enc1_2 = CBR2d(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc2_1 = CBR2d(in_channels=64, out_channels=128)\n",
    "        self.enc2_2 = CBR2d(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc3_1 = CBR2d(in_channels=128, out_channels=256)\n",
    "        self.enc3_2 = CBR2d(in_channels=256, out_channels=256)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc4_1 = CBR2d(in_channels=256, out_channels=512)\n",
    "        self.enc4_2 = CBR2d(in_channels=512, out_channels=512)\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc5_1 = CBR2d(in_channels=512, out_channels=1024)\n",
    "\n",
    "        # Expansive path (decoder)\n",
    "        self.dec5_1 = CBR2d(in_channels=1024, out_channels=512)\n",
    "\n",
    "        self.unpool4 = nn.ConvTranspose2d(in_channels=512, out_channels=512,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec4_2 = CBR2d(in_channels=2 * 512, out_channels=512)\n",
    "        self.dec4_1 = CBR2d(in_channels=512, out_channels=256)\n",
    "\n",
    "        self.unpool3 = nn.ConvTranspose2d(in_channels=256, out_channels=256,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec3_2 = CBR2d(in_channels=2 * 256, out_channels=256)\n",
    "        self.dec3_1 = CBR2d(in_channels=256, out_channels=128)\n",
    "\n",
    "        self.unpool2 = nn.ConvTranspose2d(in_channels=128, out_channels=128,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec2_2 = CBR2d(in_channels=2 * 128, out_channels=128)\n",
    "        self.dec2_1 = CBR2d(in_channels=128, out_channels=64)\n",
    "\n",
    "        self.unpool1 = nn.ConvTranspose2d(in_channels=64, out_channels=64,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec1_2 = CBR2d(in_channels=2 * 64, out_channels=64)\n",
    "        self.dec1_1 = CBR2d(in_channels=64, out_channels=64)\n",
    "\n",
    "        # output map channel을 2개 + nn.CrossEntropyLoss == output map channel을 1개 + nn.BCELoss(binary cross entropy loss)\n",
    "        # self.fc = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.fc = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "\n",
    "        dec5_1 = self.dec5_1(enc5_1)\n",
    "\n",
    "        unpool4 = self.unpool4(dec5_1)\n",
    "        cat4 = torch.cat((unpool4, enc4_2), dim=1)\n",
    "        # concatenation, dim=[0: batch, 1: channel, 2: height, 3: width]\n",
    "        dec4_2 = self.dec4_2(cat4)\n",
    "        dec4_1 = self.dec4_1(dec4_2)\n",
    "\n",
    "        unpool3 = self.unpool3(dec4_1)\n",
    "        cat3 = torch.cat((unpool3, enc3_2), dim=1)\n",
    "        dec3_2 = self.dec3_2(cat3)\n",
    "        dec3_1 = self.dec3_1(dec3_2)\n",
    "\n",
    "        unpool2 = self.unpool2(dec3_1)\n",
    "        cat2 = torch.cat((unpool2, enc2_2), dim=1)\n",
    "        dec2_2 = self.dec2_2(cat2)\n",
    "        dec2_1 = self.dec2_1(dec2_2)\n",
    "\n",
    "        unpool1 = self.unpool1(dec2_1)\n",
    "        cat1 = torch.cat((unpool1, enc1_2), dim=1)\n",
    "        dec1_2 = self.dec1_2(cat1)\n",
    "        dec1_1 = self.dec1_1(dec1_2)\n",
    "\n",
    "        x = self.fc(dec1_1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
